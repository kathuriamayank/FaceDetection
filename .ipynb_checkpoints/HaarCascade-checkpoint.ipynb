{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "face_cascade=cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "eye_cascade=cv2.CascadeClassifier(\"haarcascade_eye.xml\")\n",
    "\n",
    "img=cv2.imread(\"image.jpg\")\n",
    "#plt.imshow(img,cmap=\"gray\")\n",
    "#plt.show()\n",
    "cap=cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Now we find the faces in the image. \n",
    "If faces are found, it returns the positions of detected faces as Rect(x,y,w,h). \n",
    "Once we get these locations, we can create a ROI for the face and apply eye detection on this \n",
    "ROI (since eyes are always on the face !!! ).\n",
    "\"\"\"\n",
    "#ROI: A region of interest (ROI) is a portion of an image that you want to filter or perform some other operation on.\n",
    "#In ROI we will get eyes\n",
    "cv2.imshow(\"Colored Img\",img)\n",
    "#cv2.imshow(\"Colored Image\",img)\n",
    "img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Grayscale Image\",img_gray)\n",
    "faces=face_cascade.detectMultiScale(img_gray,1.3,5)\n",
    "\n",
    "#Getting the position of detected face as a rectangle\n",
    "for (x,y,w,h) in faces:\n",
    "\n",
    "    #img,initial points,width and height of rect,color of rect,thichkness of rect\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray=img_gray[y:y+h,x:x+w]\n",
    "    roi_color=img[y:y+h,x:x+w]\n",
    "    \n",
    "    eyes=eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "#cv2.imshow(\"image\",img)\n",
    "#cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow(\"Output Image\",img)\n",
    "cv2.imwrite(\"outputimage.jpg\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'name' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-348ebdd99b1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0mname2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mroi_gray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'name' is not defined"
     ]
    }
   ],
   "source": [
    "#Similary We Can Apply It On WebCam\n",
    "\"\"\"Now we find the faces in the image. \n",
    "If faces are found, it returns the positions of detected faces as Rect(x,y,w,h). \n",
    "Once we get these locations, we can create a ROI for the face and apply eye detection on this \n",
    "ROI (since eyes are always on the face !!! ).\n",
    "\"\"\"\n",
    "#ROI: A region of interest (ROI) is a portion of an image that you want to filter or perform some other operation on.\n",
    "i=1\n",
    "name=\"surprise\"\n",
    "while 1:\n",
    "    ret,img=cap.read()\n",
    "    img_gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces=face_cascade.detectMultiScale(img_gray)\n",
    "    for (x,y,w,h) in faces:\n",
    "        #img,initial points,width and height of rect,color of rect,thichkness\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),3)\n",
    "        roi_gray=img_gray[y:y+h,x:x+w]\n",
    "        roi_color=img[y:y+h,x:w]\n",
    "        eyes=eye_cascade.detectMultiScale(roi_gray)\n",
    "        \n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    \n",
    "    cv2.imshow(\"image\",img)\n",
    "    key=cv2.waitKey(30) & 0xff\n",
    "    if key==27:    #esc key\n",
    "       \n",
    "        break\n",
    "    if key==ord(\"s\"):\n",
    "        name=name + str(i)\n",
    "        name2=name+\".jpg\"\n",
    "        cv2.imwrite(name,roi_gray)\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
